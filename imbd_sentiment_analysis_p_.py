# -*- coding: utf-8 -*-
"""IMBD Sentiment Analysis...p....ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mI7UrRqTHkPvPEibAeAehkk6dfzbQQlD
"""

import pandas as pd

data = pd.read_csv('/content/IMDB Dataset (1).csv')

data.head(6)

for i in range(len(data['sentiment'])):
    if data['sentiment'][i] == 'positive':
        data['sentiment'][i] = 1
    else:
        data['sentiment'][i] = 0

data.head(4)

data['review'][0]

data['review'][3]

len(data)

X = data.iloc[:,0].values
y = data.iloc[:,1].values

X

y

#importing nlp libarary 
import re
from bs4 import BeautifulSoup
import numpy as np
import nltk
from nltk.corpus import stopwords

nltk.download('stopwords')

#reading english stopwords
stops = set(stopwords.words('english'))
stops

sentences = []
for i in X:
  p = i.lower()
  p = p.strip()
  p = BeautifulSoup(p).get_text()
  p = re.sub('[^a-zA-Z]', ' ', p)
  p = p.split()
  

  st = ''
  for i in p:
      if i not in stops: 
        st = st + ' ' + i
    
  sentences.append(st.strip())

print(sentences[0])

X

len(sentences)

print(sentences[0])

#Spliting 
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split( sentences, y, test_size = 0.2)

from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer()
X_train = vectorizer.fit_transform(X_train)

X_test = vectorizer.transform(X_test)

#scalling 
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()
X_train = scaler.fit_transform(X_train)

X_test = scaler.transform(X_test)

X_train.shape

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer()
X_train = vectorizer.fit_transform(X_train)

X_test = vectorizer.transform(X_test)

#convet sparce matrix to array 
X_train = X_train.toarray()
X_test = X_test.toarray()

#dimension reduction 
from sklearn.decomposition import PCA
pca = PCA(n_components=10000)

X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)

X_train.shape

y_train = list(y_train)

from sklearn.neighbors import RadiusNeighborsClassifier

clf = RadiusNeighborsClassifier(radius=1.0,  weights='uniform', algorithm='auto', leaf_size=30,p=2, metric='minkowski')
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

from sklearn.metrics import accuracy_score
 accuracy_score(y_test, y_pred)

from sklearn.tree import DecisionTreeClassifier
clf = DecisionTreeClassifier(criterion='gini', splitter = 'best', max_depth = None, min_samples_split = 2, random_state=0)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.neighbors import KNeighborsClassifier
clf = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski')
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.ensemble import GradientBoostingClassifier
clf = GradientBoostingClassifier(loss='deviance', learning_rate=0.1, n_estimators=100, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, min_impurity_split=None, init=None, random_state=None, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.ensemble import RandomForestClassifier
clf = RandomForestClassifier(n_estimators=100,  criterion='gini', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='auto', max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.neighbors import NearestCentroid
clf = NearestCentroid()
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)

from sklearn.naive_bayes import BernoulliNB
clf = BernoulliNB(alpha=1.0, binarize=0.0, fit_prior=True)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.naive_bayes import CategoricalNB
clf = CategoricalNB(alpha=1.0, fit_prior=True)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.calibration import CalibratedClassifierCV
clf = CalibratedClassifierCV(base_estimator=GaussianNB(), method='sigmoid', cv=5)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.semi_supervised import LabelPropagation
clf = LabelPropagation(gamma=20, kernel='rbf', max_iter=1000, n_neighbors=7, tol=0.001)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.semi_supervised import LabelSpreading
clf = LabelSpreading(alpha=0.2, gamma=20, kernel='rbf', max_iter=1000, n_neighbors=7, tol=0.001)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
clf = LinearDiscriminantAnalysis(n_components=None, solver='svd', tol=0.0001)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.svm import LinearSVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
clf = LinearSVC(random_state=0, fit_intercept=True,loss='squared_hinge', max_iter=1000, penalty='l2',tol=1e-5)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.svm import NuSVC
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
clf =  NuSVC(cache_size=200,decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf', max_iter=-1, nu=0.5)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.linear_model import SGDClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
# Always scale the input. The most convenient way is to use a pipeline.
clf = make_pipeline(StandardScaler(),SGDClassifier(loss='hinge', penalty='l2', alpha=0.0001, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, random_state=None, validation_fraction=0.1, n_iter_no_change=5))
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.linear_model import LogisticRegressionCV
clf = LogisticRegressionCV(Cs=10, fit_intercept=True, penalty='l2', solver='lbfgs', tol=0.0001, max_iter=100, refit=True, intercept_scaling=1.0)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.linear_model import LogisticRegression
clf = LogisticRegression(penalty='l2', dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1,  solver='lbfgs', max_iter=100, multi_class='auto')
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.linear_model import Perceptron
clf = make_pipeline(StandardScaler(),Perceptron(alpha=0.0001, early_stopping=False, eta0=1.0, fit_intercept=True, max_iter=1000, n_iter_no_change=5, random_state=0,  tol=0.001, validation_fraction=0.1))
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
kernel = 1.0 * RBF(1.0)
clf = GaussianProcessClassifier(kernel=kernel,optimizer='fmin_l_bfgs_b', n_restarts_optimizer=0, max_iter_predict=100, random_state=None, multi_class='one_vs_rest')
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB(alpha=1.0, fit_prior=True)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.naive_bayes import ComplementNB
clf = ComplementNB(alpha=1.0, fit_prior=True)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)

from sklearn.neural_network import MLPClassifier
clf = MLPClassifier(random_state=1, max_iter=300)
clf.fit(X_train,y_train)
y_pred = clf.predict(X_test)
accuracy_score(y_test, y_pred)













































































































































